visualize_simulation_results_k <- function(simulation_results) {
pivot_longer(simulation_results, c("bias2", "sd", "relativeRMSE"), names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "sd", "relativeRMSE"))) |>
ggplot(aes(h, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + facet_wrap(~k, labeller=as_labeller(c("5"="k = 5", "8"="k = 8")), scales = "free") + labs(title = "Performance Metrics of Local Average Estimator",
y = "Value",
x = "Bandwidth") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "sd" = "red", "relativeRMSE" = "green")) +
theme(legend.position = 'top')
}
# Plot
visualize_simulation_results_k(all_kdata)
set.seed(123456)
p = 5
k5 <- run_simulation(generate_predictors)
# Model
f_y_x <- function(x) {
prod = pmap_dbl(as.data.frame(x), prod)
1 + prod
}
# Define common metrics from task definition
x0s = 1
hs = seq( 1, 4, by = 0.5 )
n = 1000
set.seed(123456)
p = 5
k5 <- run_simulation(generate_predictors)
set.seed(123456)
p = 8
k8 <- run_simulation(generate_predictors)
View(k5)
set.seed(123456)
p = 8
k8 <- run_simulation(generate_predictors)
View(rbind(k5, k8))
set.seed(123456)
p = 5
k5 <- run_simulation(generate_predictors)
set.seed(123456)
p = 8
k8 <- run_simulation(generate_predictors)
View(rbind(k5, k8))
library(tidyverse)
library(glmnet)
library(factoextra)
library(pls)
install.packages('pls')
library(tidyverse)
library(glmnet)
library(factoextra)
library(pls)
theme_set(theme_minimal())
data(decathlon2)
decathlon2
knitr::opts_chunk$set(echo = T, message = F, warning = F, fig.align="center", fig.width = 8, fig.height = 5)
generate_sample <- function(n) {
e <- rnorm(length(n), mean = 0, sd = 0)
Y <- 1 + e
}
sample <- generate_sample(n)
sample <- generate_sample(10)
e <- rnorm(length(n), mean = 0, sd = 0)
generate_sample <- function(n) {
e <- rnorm(length(n), mean = 0, sd = 4)
Y <- 1 + e
}
sample <- generate_sample(10)
e <- rnorm(length(10), mean = 0, sd = 4)
e <- rnorm(n, mean = 0, sd = 4)
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
sample <- generate_sample(10)
range(20)
range(0,20)
seq(0,20)
y <- generate_sample(10)
compute_ridge <- function(lambda) {
rbeta <- sum(y)/(length(y)+lambda)
}
lapply(seq(0,20), compute_ridge())
lapply(seq(0,20), compute_ridge)
rbindlist(lapply(seq(0,20), compute_ridge))
ridgebetas <- lapply(seq(0,20), compute_ridge)
View(ridgebetas)
#generate ys from the simplest model
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
#implement derived formula for beta
compute_ridge <- function(lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(N = n, lambdas){
ridgebetas <- lapply(lambdas, compute_ridge)
}
run_simulation(10, seq(0,20))
run_simulation(n=10, lambdas=seq(0,20))
run_simulation(N=10, lambdas=seq(0,20))
#simulation
run_simulation <- function(N, lambdas){
ridgebetas <- lapply(lambdas, compute_ridge)
}
run_simulation(N=10, lambdas=seq(0,20))
#generate ys from the simplest model
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
n <- 10
#implement derived formula for beta
compute_ridge <- function(lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(n, lambdas){
ridgebetas <- lapply(lambdas, compute_ridge)
}
run_simulation(n=10, lambdas=seq(0,20))
View(ridgebetas)
run_simulation(n=10, lambdas=seq(0,20))
View(ridgebetas)
#generate ys from the simplest model
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
#implement derived formula for beta
compute_ridge <- function(lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(n, lambdas){
ridgebetas <- lapply(lambdas, compute_ridge)
}
run_simulation(n=10, lambdas=seq(0,20))
rm(ridgebetas)
run_simulation(n=10, lambdas=seq(0,20))
#simulation
run_simulation <- function(n, lambdas){
ridgebetas <- lapply(lambdas, compute_ridge)
return(ridgebetas)
}
run_simulation(n=10, lambdas=seq(0,20))
run_simulation(n=10, lambdas=seq(0,20))
run_simulation(n=10, lambdas=seq(0,20))
#generate ys from the simplest model
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
#implement derived formula for beta
compute_ridge <- function(lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
libraray(purrr)
library(purrr)
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
library(tidyverse)
library(glmnet)
library(factoextra)
library(pls)
library(purrr)
theme_set(theme_minimal())
library(tidyverse)
library(glmnet)
library(factoextra)
library(pls)
theme_set(theme_minimal())
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
View(sim1)
set.seed(1234)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation,
n = 10,
lambdas = seq(0,20)
)
n = 10,
n = 10
lambdas = seq(0,20)
set.seed(1234)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation
)
n = 10
set.seed(1234)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
View(simulation_results)
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
n = 10
# simulate 1k times
set.seed(1234)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
# add metrics
df <- group_by(simulation_results, lambda) |>
summarise(bias2 = mean(error)^2, var = var(f_star)) |>
mutate(MSE = bias2 + var)
# add metrics
df <- group_by(simulation_results, lambda) |>
summarise(bias2 = mean(error)^2, var = var(beta_star)) |>
mutate(MSE = bias2 + var)
View(simulation_results)
# add metrics
df <- group_by(simulation_results, lambda) |>
summarise(bias2 = mean(error)^2, var = var(beta_hat)) |>
mutate(MSE = bias2 + var)
View(df)
pivot_longer(df, bias2:MSE, names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "var", "MSE"))) |>
ggplot(aes(h, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + facet_wrap(~x0, labeller=as_labeller(c("0.1"="x0 = 0.1", "1"="x0 = 1")), scales = "free") + labs(title = "Performance Metrics of Local Average Estimator",
y = "Value",
x = "Bandwidth") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "var" = "red", "MSE" = "green")) +
theme(legend.position = 'top')
pivot_longer(df, bias2:MSE, names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "var", "MSE"))) |>
ggplot(aes(h, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + labs(title = "Performance Metrics of Local Average Estimator",
y = "Value",
x = "Bandwidth") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "var" = "red", "MSE" = "green")) +
theme(legend.position = 'top')
pivot_longer(df, bias2:MSE, names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "var", "MSE"))) |>
ggplot(aes(lambda, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + labs(title = "Performance Metrics of Local Average Estimator",
y = "Value",
x = "Bandwidth") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "var" = "red", "MSE" = "green")) +
theme(legend.position = 'top')
pivot_longer(df, bias2:MSE, names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "var", "MSE"))) |>
ggplot(aes(lambda, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + labs(title = "Performance Metrics of Ridge Estimator",
y = "Value",
x = "Lambda") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "var" = "red", "MSE" = "green")) +
theme(legend.position = 'top')
visualize_simulation_results <- function(simulation_results) {
pivot_longer(df, bias2:MSE, names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "var", "MSE"))) |>
ggplot(aes(lambda, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + labs(title = "Performance Metrics of Ridge Estimator",
y = "Value",
x = "Lambda") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "var" = "red", "MSE" = "green")) +
theme(legend.position = 'top')
}
#visualize
visualize_simulation_results(df)
knitr::opts_chunk$set(echo = T, message = F, warning = F, fig.align="center", fig.width = 8, fig.height = 5)
rnorm(100, 0, 1)
plot(rnorm(100, 0, 1))
plot(rnorm(100, 0, 1), rnorm(100, 0, 1))
plot(rnorm(1000, 0, 1), rnorm(1000, 0, 1))
plot(rnorm(10000, 0, 1), rnorm(10000, 0, 1))
plot(rnorm(10000, 0, 3), rnorm(10000, 0, 3))
plot(rnorm(10000, 0, 1), rnorm(10000, 0, 1))
plot(rnorm(10000, 0, 1), rnorm(10000, 0, 4))
plot(rnorm(10000, 0, 1), rnorm(10000, 0, 1))
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
compute_ridge <- function(lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
library(tidyverse)
library(glmnet)
library(factoextra)
library(pls)
theme_set(theme_minimal())
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
?rnorm
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge(n))
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
#implement derived formula for beta
compute_ridge <- function(n, lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge(n))
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
#generate ys from the simplest model
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
#implement derived formula for beta
compute_ridge <- function(n, lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge(n, .x))
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
n=10
#generate ys from the simplest model
generate_sample <- function(n) {
e <- rnorm(n, mean = 0, sd = 4)
Y <- 1 + e
}
#implement derived formula for beta
compute_ridge <- function(lambda) {
y <- generate_sample(n)
rbeta <- sum(y)/(length(y)+lambda)
}
#simulation
run_simulation <- function(lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge(n))
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(lambdas=seq(0,20))
#simulation
run_simulation <- function(lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(lambdas=seq(0,20))
kable(x = head(sim1), digits = 3, caption = 'Head of Sample') %>%
kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
library(kableExtra)
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
# simulate 1k times
set.seed(1234)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
sim1 <- run_simulation(n, lambdas=seq(0,20))
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
#simulation
run_simulation <- function(n, lambdas){
map_df(lambdas, ~{
model <- lapply(.x, compute_ridge)
tibble(
lambda = .x,
beta_hat = as.numeric(model),
beta_zero = 1,
error = beta_zero - beta_hat
)
})
}
sim1 <- run_simulation(n=10, lambdas=seq(0,20))
kable(x = head(sim1), digits = 3, caption = 'Head of Sample') %>%
kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
n = 10
# simulate 1k times
set.seed(1234)
nsim = 1000
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
simulation_results <- map_df(
seq(nsim),
run_simulation,
lambdas = seq(0,20)
)
# add metrics
df <- group_by(simulation_results, lambda) |>
summarise(bias2 = mean(error)^2, var = var(beta_hat)) |>
mutate(MSE = bias2 + var)
kable(x = head(df), digits = 3, caption = 'Head of Error metrics') %>%
kable_styling(bootstrap_options = c("striped", "hover"), full_width = F)
visualize_simulation_results <- function(simulation_results) {
pivot_longer(df, bias2:MSE, names_to = "metric") |>
mutate(metric = factor(metric, levels = c("bias2", "var", "MSE"))) |>
ggplot(aes(lambda, value, color = metric)) + geom_line(size = 1, alpha = 0.8) + labs(title = "Performance Metrics of Ridge Estimator",
y = "Value",
x = "Lambda") +
scale_color_manual(name = "Metric", values = c("bias2" = "darkblue", "var" = "red", "MSE" = "green")) +
theme(legend.position = 'top')
}
#visualize
visualize_simulation_results(df)
![pca2]('2b'){ width=50% }
setwd("~/Desktop/repos/ceu-ml/homeworks")
